{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionamento de Dados\n",
    "\n",
    "Nesse notebook serão realizados testes de benchmark em algumas colunas com o objetivo de identificar se o particionamento Hive-Style via Spark tem o mesmo desempenho que o particionamento via Z-Order + Optimize do Delta.\n",
    "\n",
    "### Queries\n",
    "\n",
    "Aqui temos as queries que serão realizadas:\n",
    "\n",
    "\n",
    "\n",
    "### Como sera o benchmark?\n",
    "\n",
    "Benchmark será feito por meio de teste de tempo e teste de files skipped. \n",
    "\n",
    "### Máquina em que foi executado:\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantas vezes um ônibus passa por um ponto de ônibus com lat e long x,y?\n",
    "Quantos ônibus ativos e qual a velocidade média deles na cidade de Curitiba numa segunda?\n",
    "Avg de velocidade e etc\n",
    "\n",
    "1 - Qual são as linhas com maior velocidade média? (AVG)\n",
    "2 - Dos ônibus que rodam o dia inteiro, quantos deles são ativos de manha? (COUNT) e qual a velocidade média deles?\n",
    "3 - Quais linhas tem mais veiculos?\n",
    "4 - Velocidade média por dia (filter and avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "* Transformar os dados em um único schema\n",
    "* Manter dois repos separados para teste\n",
    "* 1 - Testar apenas o particionamento de data\n",
    "* 2 - Testar o particionamento de hora\n",
    "* 3 - Testar o particionamento de id_onibus\n",
    "* 4 - Testar o particionamento de cidade\n",
    "* 5 - Testar o z-ordering nas mesmas colunas acima\n",
    "* 6 - Testar primeiro particionar e depois dar um z-ordering nos dados\n",
    "\n",
    "## Preparação:\n",
    "\n",
    "Definir quais podem ser as principais queries\n",
    "\n",
    "## Resultados:\n",
    "\n",
    "Tempo para cada um dos z-ordering, visualizando qual o menor tempo\n",
    "\n",
    "## Finalização\n",
    "\n",
    "Transferir tudo para o Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+--------------+--------+---------+-------------+-------------------+-------------------+\n",
      "| latitude|longitude|    bus_id|          city|bus_code|bus_speed|bus_direction|         queried_at|         updated_at|\n",
      "+---------+---------+----------+--------------+--------+---------+-------------+-------------------+-------------------+\n",
      "|-22.94364|-43.25486|RJO_A50159|Rio de Janeiro|     220|      0.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-23.01045| -43.2975|RJO_C50118|Rio de Janeiro|     302|      8.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-22.93032|-43.23769|RJO_A50025|Rio de Janeiro|     220|      0.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-23.00146|-43.36449|RJO_C50047|Rio de Janeiro|   SP805|     16.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-22.92475|-43.25124|RJO_A50187|Rio de Janeiro|     608|     27.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:49|\n",
      "|-22.92565|-43.24485|RJO_A50127|Rio de Janeiro|     608|     24.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:46|\n",
      "|-22.92509|-43.23414|RJO_C50116|Rio de Janeiro|     645|     18.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-23.00145|-43.36455|RJO_C50047|Rio de Janeiro|   SP805|     15.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:49|\n",
      "|-22.90949|-43.20941|RJO_A50002|Rio de Janeiro|     301|     28.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:47|\n",
      "|-22.93596|-43.24446|RJO_C50100|Rio de Janeiro|     301|     24.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:48|\n",
      "|-23.00155|-43.36578|RJO_C50134|Rio de Janeiro|   SP805|     11.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:50|\n",
      "|-22.94949|-43.18718|RJO_A50023|Rio de Janeiro|     157|      0.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:52|\n",
      "|-22.92421|-43.25417|RJO_A50051|Rio de Janeiro|     608|      0.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:51|\n",
      "|-22.97943|-43.29247|RJO_C50087|Rio de Janeiro|     302|     22.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:51|\n",
      "|-22.94146|-43.25234|RJO_C50110|Rio de Janeiro|     301|     20.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:51|\n",
      "|-22.92293|-43.26445|RJO_C50048|Rio de Janeiro|     608|      1.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:52|\n",
      "|-23.01012|-43.35044|RJO_C50135|Rio de Janeiro|     805|      7.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:52|\n",
      "|-22.93229|-43.24081|RJO_A50125|Rio de Janeiro|     220|     13.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:52|\n",
      "|-23.00147|-43.36476|RJO_C50047|Rio de Janeiro|   SP805|     21.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:51|\n",
      "|-23.00173| -43.3656|RJO_C50014|Rio de Janeiro|   SP805|      0.0|         NULL|2024-02-02 08:03:00|2024-02-02 08:01:52|\n",
      "+---------+---------+----------+--------------+--------+---------+-------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "\n",
    "builder = SparkSession.builder.appName(\"particionamento\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/topicos_dados/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/topicos_dados/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/topicos_dados/lake/silver\"\n",
    "BRBUS_PATH = \"/home/felipe/code/topicos_dados/lake/silver/silver_brbus/\"\n",
    "\n",
    "brbus = spark.read.format(\"delta\").load(BRBUS_PATH)\n",
    "brbus.show()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "\n",
    "builder = SparkSession.builder.appName(\"particionamento\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/topicos_dados/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/topicos_dados/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/topicos_dados/lake/silver\"\n",
    "BRBUS_PATH = \"/home/felipe/code/topicos_dados/lake/silver/silver_brbus/\"\n",
    "\n",
    "brbus = spark.read.format(\"delta\").load(BRBUS_PATH)\n",
    "brbus.createOrReplaceTempView(\"teste_brbus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 ms, sys: 1.14 ms, total: 2.89 ms\n",
      "Wall time: 760 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(bus_code='SN388', media_speed=38.45345155161495),\n",
       " Row(bus_code='SN397', media_speed=36.0497900419916),\n",
       " Row(bus_code='SR388', media_speed=31.722706691262786),\n",
       " Row(bus_code='SN554', media_speed=31.6066852367688),\n",
       " Row(bus_code='SV335', media_speed=31.398428731762063)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1 - Qual são as linhas com maior velocidade média? (AVG)\n",
    "spark.sql(\"SELECT bus_code, AVG(bus_speed) AS media_speed FROM teste_brbus WHERE city = 'Rio de Janeiro' GROUP BY bus_code ORDER BY media_speed DESC LIMIT 5;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 962 µs, sys: 655 µs, total: 1.62 ms\n",
      "Wall time: 8.39 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[bus_code: string, media_speed: double]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "spark.sql(\"SELECT bus_code, AVG(bus_speed) AS media_speed FROM teste_brbus WHERE city = 'Brasilia' AND queried_at BETWEEN '2024-02-02 08:03:00' AND '2024-02-02 22:03:00' GROUP BY bus_code ORDER BY media_speed DESC LIMIT 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 ms, sys: 1.26 ms, total: 3.25 ms\n",
      "Wall time: 813 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(data=datetime.date(2024, 1, 31), media_speed=17.63520752282458),\n",
       " Row(data=datetime.date(2024, 2, 1), media_speed=12.616950252677453),\n",
       " Row(data=datetime.date(2024, 2, 2), media_speed=15.630655713834075)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 4 - Velocidade média por dia (filter and avg)\n",
    "\n",
    "spark.sql(\"SELECT DATE(queried_at) AS data, AVG(bus_speed) AS media_speed FROM teste_brbus WHERE city = 'Rio de Janeiro' GROUP BY DATE(queried_at) ORDER BY data;\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 ms, sys: 1.57 ms, total: 4.14 ms\n",
      "Wall time: 800 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(data=datetime.date(2024, 2, 2), quantidade_onibus=3944, media_velocidade=16.645269760010176)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2 - Dos ônibus que rodam o dia inteiro, quantos deles são ativos de manha? (COUNT) e qual a velocidade média deles?\n",
    "\n",
    "spark.sql(\"SELECT DATE(queried_at) AS data,        COUNT(DISTINCT bus_id) AS quantidade_onibus,       AVG(bus_speed) AS media_velocidade FROM teste_brbus WHERE city = 'Rio de Janeiro' AND HOUR(queried_at) >= 6  AND HOUR(queried_at) < 13 GROUP BY DATE(queried_at) ORDER BY data;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 ms, sys: 0 ns, total: 1.64 ms\n",
      "Wall time: 7.47 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[bus_code: string, quantidade_veiculos: bigint]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3 - Quais linhas tem mais veiculos?\n",
    "spark.sql(\"SELECT bus_code, COUNT(DISTINCT bus_id) AS quantidade_veiculos \\\n",
    "FROM teste_brbus \\\n",
    "WHERE city = 'Rio de Janeiro' \\\n",
    "  AND DATE(queried_at) = '2024-02-02' \\\n",
    "GROUP BY bus_code \\\n",
    "ORDER BY COUNT(DISTINCT bus_id) DESC \\\n",
    "LIMIT 5; \\\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 ms, sys: 2.68 ms, total: 4.24 ms\n",
      "Wall time: 16.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Filtrando os dados\n",
    "df_filtered = brbus.filter((brbus['city'] == 'Rio de Janeiro') &\n",
    "                        (F.hour(brbus['queried_at']) >= 6) &\n",
    "                        (F.hour(brbus['queried_at']) < 13))\n",
    "\n",
    "# Criando a coluna 'data' com a data de 'queried_at'\n",
    "df_filtered = df_filtered.withColumn('data', F.to_date('queried_at'))\n",
    "\n",
    "# Calculando a contagem de ônibus distintos e a média da velocidade\n",
    "df_result = df_filtered.groupBy('data').agg(F.countDistinct('bus_id').alias('quantidade_onibus'),\n",
    "                                             F.avg('bus_speed').alias('media_velocidade'))\n",
    "\n",
    "# Ordenando os resultados pela data\n",
    "df_result = df_result.orderBy('data')\n",
    "\n",
    "# Exibindo o resultado\n",
    "# df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os snippets acima são as queries, a partir daqui iremos realizar os testes de partição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(F.col(\"country\")).write.partitionBy(\"country\").format(\n",
    "    \"delta\"\n",
    ").saveAsTable(\"country_people\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
